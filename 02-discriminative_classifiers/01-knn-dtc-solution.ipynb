{"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.6"}}, "nbformat": 4, "nbformat_minor": 2, "cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Supervised Learning\n", "\n", "To recap, just as with logistic regression, we will be analzing data coming from the US Bureau of Transportation Statistics, who recorded (a lot of) data about flights in the US from 1987 to 2008 to investigate the causes of delays.\n", "\n", "To limit this data set, we will only consider data from 2008 and selected around 100,000 instances. In cleaning the data we also removed some of the columns:\n", "\n", "* We removed non-ordinal data\n", "* We removed data that can only be known when the plane has already arrived\n", "\n", "The aim of the task is to build a classifier that can predict whether a flight will arrive with a major delay, given the parameters at takeoff. In doing so, we will run through two discriminative classifiers, namely, k-Nearest Neighbours and Decision Trees.\n", "\n", "To aim visualisation and get a sense of how the models work, we will focus on classifying major delays using only two predictor variables (Distance and Departure delay)\n", "\n", "### Loading the data\n", "\n", "As usual, let's start by loading in some essential libraries: \n", "\n", "* Import `pandas`, `numpy`, `matplotlib` and `seaborn` \n", "* Load the data corresponding to the file `flights08_cleaned.csv`\n", "* From this data, create a `major_delay` variable corresponding to the `MajorDelay` column \n", "* Finally, filter the data down to the columns `Distance` and `DepDelay`, call this `data_partial`"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Code to load the libraries\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "import seaborn as sns\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code to load the data and create a major_delay variable\n", "data_partial = ...\n", "data = pd.read_csv(\"data/flights08_clean.csv\")\n", "\n", "major_delay = data[\"MajorDelay\"]\n", "\n", "data_partial = data[[\"Distance\", \"DepDelay\"]]\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Inspect the data\n", "\n", "Before diving into any classification, feel free to familiarise yourself with the data set once more. In particular, consider using the following commands:\n", "\n", "* Do the attributes make sense? (see [here](http://stat-computing.org/dataexpo/2009/the-data.html) if you need any clarification)\n", "* What's the shape of the dataset? Consider `data_partial.shape`\n", "* How many unique values are present per attribute? Consider `data_partial.apply(pd.Series.nunique)` \n", "* What do the distributions of the variables look like?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code here to do a first exploration of the data\n", "print(\"Shape of the data: {}\\n\".format(data_partial.shape))\n", "\n", "print(\"\\nNumber of unique values?...\\n\")\n", "print(data_partial.nunique())\n", "\n", "plt.figure(figsize=(8, 6))\n", "sns.distplot(data_partial[\"DepDelay\"])\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Splitting the data into train and test sets\n", "\n", "Before fitting any models, it's important to split our data into a train and test set. As ever, sklearn has your back.\n", "\n", "Import the function `train_test_split` from `sklearn.model_selection` and check the documentation using the `?` (note that its always good practice to check the documentation!)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code to load the function and check the docs\n", "from sklearn.model_selection import train_test_split\n", "?train_test_split\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The key options that you are most likely to use are:\n", "\n", "* `test_size` a proportion so a number between 0 and 1, typically `0.2` or `0.3`\n", "* `random_state` an arbitrary integer to seed the train-test split so that your experiments are reproducible\n", "* `stratify` in the case of an imbalanced data set, you want to make sure your test set and your training set contain similar proportions of the different classes (where the classes are defined by our `major_delay` outcome variable). \n", "\n", "Create `X_train_p`, `X_test_p`, `y_train_p`, `y_test_p` out of `data_partial`, use `0.3` as proportion for test and set the random state to `101`. Specify `major_delay` as the stratifier. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code here\n", "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(data_partial, major_delay, \n", "                                                            test_size=0.3, random_state=101,\n", "                                                            stratify=major_delay)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## The kNN model\n", "\n", "As we have seen, sklearn models are really easy to use. For supervised models, all we need to do is:\n", "\n", "* Import the relevant class (here `KNeighborsClassifier` from `sklearn.neighbors`)\n", "* Generate an instance of the class specifying parameters (let's start by setting `k`, the number of neighbors, to 5)\n", "* Apply the `fit` method of the instance on the training data\n", "* Apply the `predict` method of the instance on the training data (and ultimately on the testing data)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import the class and create an instance where k (n_neighbours) equals 5\n", "from sklearn.neighbors import KNeighborsClassifier\n", "knn = KNeighborsClassifier(n_neighbors=5)\n", "\n", "# now fit it to the training data\n", "knn.fit(X_train_p, y_train_p)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Visualising Decision Boundaries\n", "\n", "You may have noticed that the fitting of the KNN model was instantaneous. This is because there is effectively no \"learning\" in the KNN model, all the computations are done at prediction time. So let's investigate the decision boundary and, in doing so, make some predictions.\n", "\n", "Inspecting the decision boundaries between our classes of interest is a good way to understand both how the KNN algorithm works and checking whether or not we have overlooked anything in our data analysis (such as whether or not our data is appropriately formatted).\n", "\n", "Displaying boundaries can be a bit involved, but is very worthwhile. In the code below we investigate our two features (`Distance` and `DepDelay`) over a grid of possible values and classify every point in the grid. Note that, in this example, we only have two features so can plot a 2D grid: in a more typical classification problem we would have many more features which would be much harder to visualise in a meaningful way.\n", "\n", "Let's do this for our two features:\n", "* Create a meshgrid of possible values for our features (using `np.meshgrid`), say, $100\\times100$\n", "* Then, for every point in the grid, use the KNN model to classify each point and store in the vector `Z`\n", "* Reshape `Z` so that is has the shape of the grid\n", "* Use `pcolormesh` to display the result of the classification\n", "\n", "[This tutorial](http://scikit-learn.org/stable/auto_examples/neighbors/plot_nearest_centroid.html) does something fairly similar and may prove helpful if you need further clarification about this process (sklearn has some very good tutorials!)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# First, we find the minimum and maximum values for our features\n", "x_min, x_max = 0, data_partial['Distance'].max()\n", "y_min, y_max = data_partial['DepDelay'].min(), data_partial['DepDelay'].max()\n", "\n", "# Then create a meshgrid of 100 evenly spaced values over these ranges\n", "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n", "                     np.linspace(y_min, y_max, 100))\n", "\n", "# Create our predicted class vector, Z. Note that we reshape this later to match the meshgrid's shape\n", "Z = np.zeros(100*100)\n", "\n", "# To facilitate iterating over the meshgrid, flatten xx and yy into vectors \n", "xxr = xx.ravel()\n", "yyr = yy.ravel()\n", "\n", "# Then iterate over each cell in the meshgrid and classify the values of Distance and CRSDepTime\n", "for i in range(len(Z)):\n", "    Z[i] = knn.predict(np.array([xxr[i], yyr[i]]).reshape(1, -1))[0]\n", "\n", "# Reshape the vector of predicted values so that it has the same shape as the meshgrid\n", "Z = Z.reshape(xx.shape)\n", "\n", "# Finally, display the results using pcolormesh\n", "plt.figure(figsize=(8, 6))\n", "cmap = plt.get_cmap('Blues', 2)\n", "plt.pcolormesh(xx, yy, Z, cmap=cmap)\n", "plt.colorbar(ticks=[0, 1])\n", "plt.xlabel(\"Distance\")\n", "plt.ylabel(\"DepDelay\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Tuning the k Parameter\n", "\n", "As the plot above indicates, our model with `k` set to 5 creates a fairly linear decision boundary: flights delayed by approximately 50 minutes or more are classified as major delays and while there is some variation over flight distance, this effect is muted.\n", "\n", "However, this boundary is highly dependent on the parameter `k` which represents the number of nearest training samples that are used to classify an unlabeled data point.\n", "\n", "A key part of the k-Nearest Neighborhood algorithm is the choice of k. So far, we have been using a value of 5. In this case, each new data point is predicted by the labels of its nearest 5 neighbours in the training set. However, `k` is a parameter which can and should be tuned. It can take any value from 1 to the number of data points in the training set.\n", "\n", "To demonstrate this, let's consider what happens to the decision boundary as we increase the number of neighbours we use to predict class labels for new data points. Let's try four different values of `k`:\n", "* Create a list of `k` values to investigate, for example: `parameters = [5, 50, 100, 500]`\n", "* Write a for loop over this list which instantiates the KNN object with the k parameter\n", "* Fit this KNN object with our training data\n", "* Call `plot_function` which will plot a decision boundary as in the previous code block"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_function(knn_model):\n", "    # As before, identify the range of our two features\n", "    x_min, x_max = 0, data_partial['Distance'].max()\n", "    y_min, y_max = data_partial['DepDelay'].min(), data_partial['DepDelay'].max()\n", "\n", "    # Create a meshgrid of 100 evenly spaced values over these ranges\n", "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n", "                         np.linspace(y_min, y_max, 100))\n", "    \n", "    # Use the passed KNN object to predict values\n", "    Z = knn_model.predict(np.c_[xx.ravel(), yy.ravel()])\n", "    Z = Z.reshape(xx.shape).astype(float)\n", "    \n", "    # Finally, display the results using pcolormesh\n", "    plt.figure(figsize=(8, 6))\n", "    cmap = plt.get_cmap('Blues', 2)\n", "    plt.pcolormesh(xx, yy, Z, cmap=cmap)\n", "    plt.colorbar(ticks=[0, 1])\n", "    plt.xlabel(\"Distance\")\n", "    plt.ylabel(\"DepDelay\")\n", "    plt.show()\n", "\n", "    \n", "# Create a list of k values to investigate and then call plot_function on the fitted object\n", "parameters = [5, 50, 100, 500]\n", "\n", "for k in parameters:\n", "    knn = KNeighborsClassifier(n_neighbors=k)\n", "    knn.fit(X_train_p,y_train_p)\n", "    plot_function(knn)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Training and Testing Accuracy over k\n", "\n", "As you can see, the decision boundary can be highly sensitive to the `k` parameter. This boundary is essential to the performance of the overall model. So far, however, we have only considered a simplified, two-feature model. To get a better sense of how the classifer's performance is influenced by the choice of the `k` parameter, we need to train our model on the full data set.\n", "\n", "Let's reload the original data and train a full model to investigate how training and testing accuracy is influenced by our choice of `k`:\n", "\n", "* From our `data` dataframe, drop the `MajorDelay` column as we already have this information in the `major_delay` variable\n", "* Create `X_train`, `X_test`, `y_train`, `y_test` out of `data` and `major_delay` from the sklearn `train_test_split` function. Again, use `0.3` as proportion for test and set the random state to `101`. Specify `major_delay` as the stratifier"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Reload the data file, drop the MajorDelay variable, and create training and test data sets\n", "major_delay = data[\"MajorDelay\"]\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(data.drop('MajorDelay', axis=1), major_delay, \n", "                                                    test_size=0.3, random_state=101,\n", "                                                    stratify=major_delay)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["After running these preparatory steps, we can then iterate over a number of values of `k`, training and evaluating KNNs at each iteration. To do so, we need to create variables to store our parameters of `k`, the classifier's training performance, and the classifier's test performance:\n", "\n", "* Create a list of `k` values to investigate, for example: `parameters = [5, 25, 50, 100]`\n", "* Then create two empty lists, `train_accuracy` and `test_accuracy`\n", "* Write a for loop over `parameters` which instantiates the KNN object with the `k` parameter\n", "* Fit this KNN object with our training data and, using the `score()` method append the training accuracy and the test accuracy to their respective lists\n", "* Finally, call the `plot_train_test_accuracy` function with arguments `parameters`, `training_accuracy`, and `test_accuracy`"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false}, "outputs": [], "source": ["def plot_train_test_accuracy(k, train_accuracy, test_accuracy):\n", "    plt.figure(figsize=(8, 6))\n", "    \n", "    plt.plot(k, train_accuracy, linewidth=2.0, color='r', label=\"Train Accuracy\")\n", "    plt.plot(k, test_accuracy, linewidth=2.0, color='b', label=\"Test Accuracy\")\n", "    \n", "    plt.xlabel(\"k\")\n", "    plt.ylabel(\"Accuracy\")\n", "    plt.legend(loc='upper right')\n", "    plt.show()\n", "\n", "# + Create two empty lists for train and test accuracy then iterate over a list of k values\n", "train_accuracy = []\n", "test_accuracy = []\n", "\n", "parameters = [1, 2, 3, 4, 5, 25, 50, 100]\n", "\n", "for k in parameters:\n", "    knn = KNeighborsClassifier(n_neighbors=k)\n", "    knn.fit(X_train,y_train)\n", "    train_accuracy.append(knn.score(X_train,y_train))\n", "    test_accuracy.append(knn.score(X_test,y_test))\n", "    \n", "plot_train_test_accuracy(parameters, train_accuracy, test_accuracy)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Bias and Variance\n", "\n", "In this case, our KNN demonstrates good training performance across values of `k`, up to around `1000`. Importantly, the model's accuracy is similar across both training and test data sets. This is a good indication that the model has not overfitted on the training set: if it were, we would expect a substantial drop in performance on the test set as the model failed to generalise to unseen data points. \n", "\n", "Considering the plot above, and the decision boundaries that we generated earlier, it is worth discussing model complexity. Increasing `k` results in averaging more nearest neighbours to label unseen data points, which results in smoother decision boundaries (compare $k=5$ to $k=500$). With $k=1$, however, the separation between our two classes is jagged and islands appear. \n", "\n", "The value of `k` indicates the degree of model complexity, and relates to the concepts of bias and variance. While bias arises from erroneous assumptions in the model's specification, variance arises from high sensitivity to variations in the training set.\n", "\n", "When `k` is equal to `1`, our model is most complex. At this point, are we observing high variance or high bias? What happens to the bias as we increase `k`?\n", "\n", "### Limitations\n", "\n", "Before investigating other classifiers, it is worth considering some of the shortcomings of our data set. For instance, we included in our model the days of the week (`DayOfWeek`). When handling this data, the KNN treats Mondays (`1`) as maximally different to Sundays (`7`). Why might this be a problem? Can you identify any other features which might have similar shortcomings?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Decision Tree Classifier (DTC)\n", "\n", "Just as with KNN, sklearn provides an easy, highly optimised implementation for DTCs. A DTC has a hierarchical structure, where each node corresponds to a feature and a split. To get started with DTCs, let's build a simple model with a maximum depth (i.e. number of splits) of `2`:\n", "\n", "* Import the relevant class (here `DecisionTreeClassifier` from `sklearn.tree`)\n", "* Inspect the documentation using `?`\n", "* Instantiate the `DecisionTreeClassifer` object with `max_depth` set to `2`\n", "* Fit the object on `X_train` and `y_train`"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code to import the object and check the docs\n", "from sklearn.tree import DecisionTreeClassifier\n", "?DecisionTreeClassifier\n", "\n", "# Create an instance where max_depth equals 2 and fit it to the training data\n", "dtc = DecisionTreeClassifier(max_depth=3)\n", "\n", "dtc.fit(X_train, y_train)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Visualising the DTC\n", "\n", "Using the `graphviz` package, we can easily visualise the tree structure in the notebook. To do so execute the cell below. For more information, see the [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.tree import export_graphviz\n", "import graphviz\n", "dot_data = export_graphviz(dtc, out_file=None, \n", "    feature_names=X_train.columns,  \n", "    class_names=['not delayed', 'delayed'],  \n", "    filled=True, rounded=True,  \n", "    special_characters=True, rotate=True)\n", "graph = graphviz.Source(dot_data)\n", "graph"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Visualising Decision Boundaries\n", "\n", "As in the case for KNNs, let's visualise the decision boundary using two of the features in our data set (again, we use `Distance` and `DepDelay`).\n", "\n", "Since we have the variables already loaded, we can use `X_train_p`, `y_train_p`, etc. Start by fitting a more complex tree with at least 5 levels, then:\n", "\n", "* Create a meshgrid of possible values for our features (using `np.meshgrid`), say, $100\\times100$\n", "* Then, for every point in the grid, use the DTC model to classify each point and store in the vector `Z`\n", "* Reshape `Z` so that is has the shape of the grid\n", "* Use `pcolormesh` to display the result of the classification\n", "\n", "Can you interpret the decision boundary?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# First, create a DTC with max_depth equal to 5 and fit it:\n", "dtc = DecisionTreeClassifier(max_depth=5)\n", "dtc.fit(X_train_p, y_train_p)\n", "\n", "# Second, we find the minimum and maximum values for our features\n", "x_min, x_max = 0, data['Distance'].max()\n", "y_min, y_max = data['DepDelay'].min(), data['DepDelay'].max()\n", "\n", "# Then create a meshgrid of 100 evenly spaced values over these ranges\n", "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n", "                     np.linspace(y_min, y_max, 100))\n", "\n", "# Create our predicted class vector, Z. Note that we reshape this later to match the meshgrid's shape\n", "Z = np.zeros(100*100)\n", "\n", "# To facilitate iterating over the meshgrid, flatten xx and yy into vectors \n", "xxr = xx.ravel()\n", "yyr = yy.ravel()\n", "\n", "# Then iterate over each cell in the meshgrid and classify the values of Distance and CRSDepTime\n", "dtc.predict(np.array([xxr[0], yyr[0]]).reshape(1, -1))[0]\n", "\n", "for i in range(len(Z)):\n", "    Z[i] = dtc.predict(np.array([xxr[i], yyr[i]]).reshape(1, -1))[0]\n", "\n", "# Reshape the vector of predicted values so that it has the same shape as the meshgrid\n", "Z = Z.reshape(xx.shape)\n", "\n", "# Finally, display the results using pcolormesh\n", "plt.figure(figsize=(8, 6))\n", "cmap = plt.get_cmap('Blues', 2)\n", "plt.pcolormesh(xx, yy, Z, cmap=cmap)\n", "plt.colorbar(ticks=[0, 1])\n", "plt.xlabel(\"Distance\")\n", "plt.ylabel(\"DepDelay\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Tuning DTC depth\n", "\n", "In a DTC the decision boundary is a visual representation of the hierarchical variable thresholds explicitly described by the nodes of the tree itself.\n", "\n", "However, this boundary is sensitive to the depth of the tree. To demonstrate this, let's consider what happens to the decision boundary as we inspect the decision boundary over a range of `max_depth` values:\n", "\n", "* Create a list of `max_depth` to investigate, for example: `depths = [2, 5, 10, 50, 100]\n", "* Write a for loop over this list which instantiates the DTC object with the `max_depth` parameter\n", "* Fit this DTC object with our partial training data\n", "* Call `plot_function` which will plot a decision boundary "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_function(dtc_model):\n", "    # As before, identify the range of our two features\n", "    x_min, x_max = 0, data_partial['Distance'].max()\n", "    y_min, y_max = data_partial['DepDelay'].min(), data_partial['DepDelay'].max()\n", "\n", "    # Create a meshgrid of 100 evenly spaced values over these ranges\n", "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n", "                         np.linspace(y_min, y_max, 100))\n", "    \n", "    # Use the passed DTC object to predict values\n", "    Z = dtc_model.predict(np.c_[xx.ravel(), yy.ravel()])\n", "    Z = Z.reshape(xx.shape).astype(float)\n", "    \n", "    # Finally, display the results using pcolormesh\n", "    plt.figure(figsize=(8, 6))\n", "    cmap = plt.get_cmap('Blues', 2)\n", "    plt.pcolormesh(xx, yy, Z, cmap=cmap)\n", "    plt.colorbar(ticks=[0, 1])\n", "    plt.xlabel(\"Distance\")\n", "    plt.ylabel(\"DepDelay\")\n", "    plt.show()\n", "\n", "    \n", "# Create a list of depth values to investigate and then call plot_function on the fitted object\n", "depths = [5, 10, 50, 100]\n", "\n", "for d in depths:\n", "    dtc = DecisionTreeClassifier(max_depth=d)\n", "    dtc.fit(X_train_p, y_train_p)\n", "    plot_function(dtc)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Training and Testing Accuracy over DTC depth\n", "\n", "As you can see, the decision boundary can be quite sensitive to the `max_depth` parameter. While this boundary is essential to the predictions of the model, we have only considered a simple, two-feature model.\n", "\n", "To get a better sense of how the classifer's performance is influenced by the choice of the `max_depth` parameter, we need to train our model on the full data set:\n", "\n", "* Create a list of `max_depth` values to investigate, for example: `depths = [1, 2, 5, 10, 50, 100]`\n", "* Then create two empty lists, `train_accuracy` and `test_accuracy`\n", "* Write a for loop over `parameters` which instantiates the DTC object with the `max_depth` parameter\n", "* Fit this DTC object with our training data and, using the `score()` method append the training accuracy and the test accuracy to their respective lists\n", "* Finally, call the `plot_train_test_accuracy` function with arguments `depths`, `training_accuracy`, and `test_accuracy`\n", "\n", "(**Bonus**) if you have time, try to explore the parameters of the DTC. What do they mean? Do they help? See also the [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier). "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_train_test_accuracy(depth, train_accuracy, test_accuracy):\n", "    plt.figure(figsize=(8, 6))\n", "    \n", "    plt.plot(depth, train_accuracy, linewidth=2.0, color='r', label=\"Train Accuracy\")\n", "    plt.plot(depth, test_accuracy, linewidth=2.0, color='b', label=\"Test Accuracy\")\n", "    \n", "    plt.xlabel(\"Max Depth\")\n", "    plt.ylabel(\"Accuracy\")\n", "    plt.legend(loc='upper right')\n", "    plt.show()\n", "\n", "# Create two empty lists for train and test accuracy then iterate over a list of depths\n", "train_accuracy = []\n", "test_accuracy = []\n", "\n", "depths = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 50, 100]\n", "\n", "for d in depths:\n", "    dtc = DecisionTreeClassifier(max_depth=d)\n", "    dtc.fit(X_train, y_train)\n", "    train_accuracy.append(dtc.score(X_train,y_train))\n", "    test_accuracy.append(dtc.score(X_test,y_test))\n", "    \n", "plot_train_test_accuracy(depths, train_accuracy, test_accuracy)\n"]}, {"cell_type": "markdown", "metadata": {"collapsed": true}, "source": ["### Assessing DTC Performance\n", "\n", "Unlike a KNN, where the model is most complex where `k` equals `1`, in a DTC, the deeper the tree (i.e. the larger `max_depth` is), the more complex the model. This is sharply evidenced in the performance over a range of `max_depth` values: performance on the training set and test set diverges as the DTC gets deeper. \n", "\n", "This means that the deeper the tree, the higher the variance. In the plot above, where is the point of highest bias? What would happen if we kept increasing `max_depth`?\n", "\n", "How does this model compare to KNNs? Before introducing the DTC model, we noted that KNNs treat Mondays (`1`) as maximally different from Sundays (`7`) and queried whether or not this was a drawback of the model. Do DTCs suffer from the same limitation? What happens if the training data changes?\n", "\n"]}]}